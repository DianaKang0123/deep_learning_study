{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5e862f-3d97-44fc-a40d-c50ea3c5c493",
   "metadata": {},
   "source": [
    "### Callback API Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97295ee7-1365-4847-abf5-41f988bae706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset shape: (60000, 28, 28) (60000,)\n",
      "test dataset shape: (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(\"train dataset shape:\", train_images.shape, train_labels.shape)\n",
    "print(\"test dataset shape:\", test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8339a4-b327-41aa-ad3c-d2280d570fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer,Dense,Flatten,Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "\n",
    "def create_model():\n",
    "    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n",
    "    x = Flatten()(input_tensor)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47158bf4-0f2e-472e-8fa4-f083d5a5bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def get_preprocessed_data(images, targets):\n",
    "    images = np.array(images / 255.0, dtype=np.float32)\n",
    "    targets = np.array(targets, dtype=np.float32)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "def get_preprocessed_ohe(images, targets):\n",
    "    images, targets = get_preprocessed_data(images, targets)\n",
    "    oh_targets = to_categorical(targets)\n",
    "\n",
    "    return images, oh_targets\n",
    "\n",
    "def get_train_valid_test(train_images, train_targets, test_images, test_targets, validation_size=0.2, random_state=124):\n",
    "    train_images, train_oh_targets = get_preprocessed_ohe(train_images, train_targets)\n",
    "    test_images, test_oh_targets = get_preprocessed_ohe(test_images, test_targets)\n",
    "\n",
    "    train_images, validation_images, train_oh_targets, validation_oh_targets = \\\n",
    "    train_test_split(train_images, train_oh_targets, stratify=train_oh_targets, test_size=validation_size, random_state=random_state)\n",
    "\n",
    "    return (train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c669d92-23aa-426f-a40a-8257da9c8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28) (48000, 10)\n",
      "(12000, 28, 28) (12000, 10)\n",
      "(10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_targets), (test_images, test_targets) = mnist.load_data()\n",
    "\n",
    "(train_images, train_oh_targets), (validation_images, validation_oh_targets), (test_images, test_oh_targets) = \\\n",
    "get_train_valid_test(train_images, train_targets, test_images, test_targets)\n",
    "\n",
    "print(train_images.shape, train_oh_targets.shape)\n",
    "print(validation_images.shape, validation_oh_targets.shape)\n",
    "print(test_images.shape, test_oh_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7596315a-736b-4044-8b24-56d196a87d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - acc: 0.8329 - loss: 0.5895 - val_acc: 0.9459 - val_loss: 0.1855\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - acc: 0.9519 - loss: 0.1617 - val_acc: 0.9546 - val_loss: 0.1473\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - acc: 0.9677 - loss: 0.1070 - val_acc: 0.9665 - val_loss: 0.1092\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - acc: 0.9754 - loss: 0.0830 - val_acc: 0.9712 - val_loss: 0.0991\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - acc: 0.9812 - loss: 0.0647 - val_acc: 0.9751 - val_loss: 0.0864\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 922us/step - acc: 0.9845 - loss: 0.0518 - val_acc: 0.9722 - val_loss: 0.0950\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - acc: 0.9868 - loss: 0.0429 - val_acc: 0.9728 - val_loss: 0.0901\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - acc: 0.9888 - loss: 0.0362 - val_acc: 0.9760 - val_loss: 0.0840\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - acc: 0.9906 - loss: 0.0309 - val_acc: 0.9736 - val_loss: 0.0957\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968us/step - acc: 0.9914 - loss: 0.0266 - val_acc: 0.9766 - val_loss: 0.0872\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - acc: 0.9929 - loss: 0.0221 - val_acc: 0.9761 - val_loss: 0.0869\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - acc: 0.9947 - loss: 0.0185 - val_acc: 0.9742 - val_loss: 0.0983\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - acc: 0.9944 - loss: 0.0172 - val_acc: 0.9758 - val_loss: 0.0968\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - acc: 0.9950 - loss: 0.0146 - val_acc: 0.9760 - val_loss: 0.1032\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906us/step - acc: 0.9949 - loss: 0.0146 - val_acc: 0.9754 - val_loss: 0.0996\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - acc: 0.9974 - loss: 0.0103 - val_acc: 0.9753 - val_loss: 0.1083\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step - acc: 0.9958 - loss: 0.0117 - val_acc: 0.9760 - val_loss: 0.1052\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - acc: 0.9974 - loss: 0.0089 - val_acc: 0.9743 - val_loss: 0.1176\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - acc: 0.9977 - loss: 0.0072 - val_acc: 0.9767 - val_loss: 0.1087\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - acc: 0.9973 - loss: 0.0081 - val_acc: 0.9750 - val_loss: 0.1246\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# mcp_cb = ModelCheckpoint(\n",
    "#     filepath=\"./callback_files/model.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.model.keras\",\n",
    "#     monitor='val_loss',\n",
    "#     # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "#     save_best_only=False,\n",
    "#     save_weights_only=False,\n",
    "#     mode='min'\n",
    "# )\n",
    "\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_targets, \n",
    "                    validation_data=(validation_images, validation_oh_targets), \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    callbacks=[mcp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "514fad88-6fa0-4f51-b396-f215895846af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C 드라이브의 볼륨에는 이름이 없습니다.\n",
      " 볼륨 일련 번호: DADA-845F\n",
      "\n",
      " C:\\KDT_231228_khj\\ai\\deep_learning\\c_tensorflow\\callback_files 디렉터리\n",
      "\n",
      "2024-05-28  오전 10:58    <DIR>          .\n",
      "2024-05-28  오전 10:57    <DIR>          ..\n",
      "2024-05-28  오전 10:57           743,334 model.001-0.1817-0.9029.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.002-0.1244-0.9559.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.003-0.1135-0.9685.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.004-0.0973-0.9747.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.005-0.0977-0.9798.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.006-0.0912-0.9823.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.007-0.1068-0.9849.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.008-0.0936-0.9872.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.009-0.1140-0.9900.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.010-0.1046-0.9906.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.011-0.0956-0.9914.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.012-0.1038-0.9934.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.013-0.1066-0.9939.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.014-0.1114-0.9936.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.015-0.1085-0.9950.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.016-0.1074-0.9943.model.keras\n",
      "2024-05-28  오전 10:57           743,334 model.017-0.1182-0.9958.model.keras\n",
      "2024-05-28  오전 10:58           743,334 model.018-0.1255-0.9961.model.keras\n",
      "2024-05-28  오전 10:58           743,334 model.019-0.1182-0.9958.model.keras\n",
      "2024-05-28  오전 10:58           743,334 model.020-0.1358-0.9966.model.keras\n",
      "2024-05-28  오전 10:57           739,600 weights.001-0.1838-0.9028.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.002-0.1437-0.9543.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.003-0.1218-0.9662.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.004-0.1004-0.9736.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.005-0.0997-0.9793.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.006-0.1161-0.9821.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.007-0.0938-0.9857.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.008-0.1040-0.9867.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.009-0.0978-0.9885.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.010-0.0994-0.9908.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.011-0.0949-0.9918.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.012-0.1017-0.9931.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.013-0.1186-0.9929.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.014-0.1038-0.9944.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.015-0.1092-0.9944.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.016-0.1057-0.9950.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.017-0.1051-0.9961.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.018-0.1098-0.9968.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.019-0.1210-0.9951.weights.h5\n",
      "2024-05-28  오전 10:57           739,600 weights.020-0.1166-0.9968.weights.h5\n",
      "              40개 파일          29,658,680 바이트\n",
      "               2개 디렉터리  1,789,172,371,456 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir callback_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75761fab-604f-4d3c-8f47-6f5312afa860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - acc: 0.9717 - loss: 0.1438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1287546455860138, 0.9750999808311462]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddd1d0d9-1a24-4351-95a5-7d2ca78016e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - acc: 0.9689 - loss: 0.0964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08809623122215271, 0.9729999899864197]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights('./callback_files/weights.008-0.0840-0.9875.weights.h5')\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d68b254-4216-4629-b2e0-c77c1afdd44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - acc: 0.9689 - loss: 0.0964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08809623122215271, 0.9729999899864197]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9a3f1b0-e61a-4629-9301-1656eb30af5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - acc: 0.9694 - loss: 0.1559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13407786190509796, 0.973800003528595]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26888bfb-d8e5-4cb3-8c2b-921ca69163f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - acc: 0.9713 - loss: 0.1040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09351637214422226, 0.974399983882904]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('./callback_files/model.008-0.0906-0.9866.model.keras')\n",
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c643f869-c669-457d-9281-fb5a1ddcf633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - acc: 0.9713 - loss: 0.1040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09351637214422226, 0.974399983882904]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_oh_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac24e7c3-f3a9-4306-9516-ccd358737ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8186 - loss: 0.6133 - val_acc: 0.9493 - val_loss: 0.1750 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - acc: 0.9570 - loss: 0.1476 - val_acc: 0.9602 - val_loss: 0.1267 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - acc: 0.9707 - loss: 0.0984 - val_acc: 0.9641 - val_loss: 0.1168 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - acc: 0.9767 - loss: 0.0740 - val_acc: 0.9704 - val_loss: 0.0941 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - acc: 0.9822 - loss: 0.0605 - val_acc: 0.9712 - val_loss: 0.0940 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 829us/step - acc: 0.9842 - loss: 0.0515 - val_acc: 0.9714 - val_loss: 0.0940 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825us/step - acc: 0.9867 - loss: 0.0424 - val_acc: 0.9676 - val_loss: 0.1099 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - acc: 0.9929 - loss: 0.0261 - val_acc: 0.9758 - val_loss: 0.0785 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step - acc: 0.9962 - loss: 0.0173 - val_acc: 0.9772 - val_loss: 0.0779 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - acc: 0.9962 - loss: 0.0169 - val_acc: 0.9769 - val_loss: 0.0778 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - acc: 0.9963 - loss: 0.0166 - val_acc: 0.9775 - val_loss: 0.0776 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - acc: 0.9969 - loss: 0.0135 - val_acc: 0.9776 - val_loss: 0.0772 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - acc: 0.9972 - loss: 0.0136 - val_acc: 0.9767 - val_loss: 0.0797 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - acc: 0.9977 - loss: 0.0128 - val_acc: 0.9779 - val_loss: 0.0780 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - acc: 0.9982 - loss: 0.0113 - val_acc: 0.9778 - val_loss: 0.0777 - learning_rate: 1.0000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - acc: 0.9979 - loss: 0.0113 - val_acc: 0.9777 - val_loss: 0.0779 - learning_rate: 1.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - acc: 0.9980 - loss: 0.0109 - val_acc: 0.9778 - val_loss: 0.0779 - learning_rate: 1.0000e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - acc: 0.9983 - loss: 0.0106 - val_acc: 0.9778 - val_loss: 0.0779 - learning_rate: 1.0000e-06\n",
      "Epoch 19/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - acc: 0.9982 - loss: 0.0108 - val_acc: 0.9778 - val_loss: 0.0779 - learning_rate: 1.0000e-07\n",
      "Epoch 20/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - acc: 0.9983 - loss: 0.0102 - val_acc: 0.9778 - val_loss: 0.0779 - learning_rate: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_targets, \n",
    "                    validation_data=(validation_images, validation_oh_targets), \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    callbacks=[rlr_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bd269d9-0850-4708-a0e4-4008c839759a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8253 - loss: 0.5982 - val_acc: 0.9463 - val_loss: 0.1817\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - acc: 0.9532 - loss: 0.1586 - val_acc: 0.9506 - val_loss: 0.1561\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step - acc: 0.9663 - loss: 0.1120 - val_acc: 0.9666 - val_loss: 0.1108\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - acc: 0.9766 - loss: 0.0779 - val_acc: 0.9662 - val_loss: 0.1080\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880us/step - acc: 0.9810 - loss: 0.0637 - val_acc: 0.9688 - val_loss: 0.0962\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - acc: 0.9845 - loss: 0.0529 - val_acc: 0.9633 - val_loss: 0.1216\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 836us/step - acc: 0.9866 - loss: 0.0439 - val_acc: 0.9699 - val_loss: 0.0979\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_targets, \n",
    "                    validation_data=(validation_images, validation_oh_targets), \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    callbacks=[ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42d7000f-b917-4006-8c3e-b9e1f7b281d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.8280 - loss: 0.6067 - val_acc: 0.9444 - val_loss: 0.1835 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946us/step - acc: 0.9540 - loss: 0.1584 - val_acc: 0.9604 - val_loss: 0.1343 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - acc: 0.9675 - loss: 0.1102 - val_acc: 0.9674 - val_loss: 0.1076 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - acc: 0.9770 - loss: 0.0785 - val_acc: 0.9683 - val_loss: 0.1044 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - acc: 0.9802 - loss: 0.0627 - val_acc: 0.9681 - val_loss: 0.1027 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - acc: 0.9846 - loss: 0.0524 - val_acc: 0.9680 - val_loss: 0.1049 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - acc: 0.9851 - loss: 0.0458 - val_acc: 0.9742 - val_loss: 0.0895 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - acc: 0.9890 - loss: 0.0345 - val_acc: 0.9716 - val_loss: 0.0910 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - acc: 0.9906 - loss: 0.0291 - val_acc: 0.9758 - val_loss: 0.0901 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])\n",
    "\n",
    "mcp_cb = ModelCheckpoint(\n",
    "    filepath=\"./callback_files/weights.{epoch:03d}-{val_loss:.4f}-{acc:.4f}.weights.h5\",\n",
    "    monitor='val_loss',\n",
    "    # 모든 epoch의 파일을 저장하지 않고 좋은 성능이라 판단될 경우만 저장할 때 True설정\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "rlr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "ely_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history = model.fit(x=train_images, \n",
    "                    y=train_oh_targets, \n",
    "                    validation_data=(validation_images, validation_oh_targets), \n",
    "                    batch_size=64, \n",
    "                    epochs=20, \n",
    "                    callbacks=[mcp_cb, rlr_cb, ely_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd3140-b07e-4111-9dc6-bbe6c9c52893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801ee77-8e35-490c-83bf-13403ab1d24e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
